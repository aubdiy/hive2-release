PREHOOK: query: create table daysales (customer int) partitioned by (dt string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@daysales
POSTHOOK: query: create table daysales (customer int) partitioned by (dt string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@daysales
PREHOOK: query: insert into daysales partition(dt='2001-01-01') values(1)
PREHOOK: type: QUERY
PREHOOK: Input: default@values__tmp__table__1
PREHOOK: Output: default@daysales@dt=2001-01-01
POSTHOOK: query: insert into daysales partition(dt='2001-01-01') values(1)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@values__tmp__table__1
POSTHOOK: Output: default@daysales@dt=2001-01-01
POSTHOOK: Lineage: daysales PARTITION(dt=2001-01-01).customer EXPRESSION [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
PREHOOK: query: insert into daysales partition(dt='2001-01-03') values(3)
PREHOOK: type: QUERY
PREHOOK: Input: default@values__tmp__table__2
PREHOOK: Output: default@daysales@dt=2001-01-03
POSTHOOK: query: insert into daysales partition(dt='2001-01-03') values(3)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@values__tmp__table__2
POSTHOOK: Output: default@daysales@dt=2001-01-03
POSTHOOK: Lineage: daysales PARTITION(dt=2001-01-03).customer EXPRESSION [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
PREHOOK: query: select * from daysales where nvl(dt='2001-01-01' and customer=1, false)
PREHOOK: type: QUERY
PREHOOK: Input: default@daysales
PREHOOK: Input: default@daysales@dt=2001-01-01
#### A masked pattern was here ####
POSTHOOK: query: select * from daysales where nvl(dt='2001-01-01' and customer=1, false)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@daysales
POSTHOOK: Input: default@daysales@dt=2001-01-01
#### A masked pattern was here ####
1	2001-01-01
PREHOOK: query: select * from daysales where nvl(dt='2001-01-02' and customer=1, false)
PREHOOK: type: QUERY
PREHOOK: Input: default@daysales
#### A masked pattern was here ####
POSTHOOK: query: select * from daysales where nvl(dt='2001-01-02' and customer=1, false)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@daysales
#### A masked pattern was here ####
PREHOOK: query: select * from daysales where nvl(dt='2001-01-01' and customer=1, true)
PREHOOK: type: QUERY
PREHOOK: Input: default@daysales
PREHOOK: Input: default@daysales@dt=2001-01-01
#### A masked pattern was here ####
POSTHOOK: query: select * from daysales where nvl(dt='2001-01-01' and customer=1, true)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@daysales
POSTHOOK: Input: default@daysales@dt=2001-01-01
#### A masked pattern was here ####
1	2001-01-01
PREHOOK: query: select * from daysales where (dt='2001-01-01' and customer=1)
PREHOOK: type: QUERY
PREHOOK: Input: default@daysales
PREHOOK: Input: default@daysales@dt=2001-01-01
#### A masked pattern was here ####
POSTHOOK: query: select * from daysales where (dt='2001-01-01' and customer=1)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@daysales
POSTHOOK: Input: default@daysales@dt=2001-01-01
#### A masked pattern was here ####
1	2001-01-01
PREHOOK: query: select * from daysales where (dt='2001-01-01' or customer=3)
PREHOOK: type: QUERY
PREHOOK: Input: default@daysales
PREHOOK: Input: default@daysales@dt=2001-01-01
PREHOOK: Input: default@daysales@dt=2001-01-03
#### A masked pattern was here ####
POSTHOOK: query: select * from daysales where (dt='2001-01-01' or customer=3)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@daysales
POSTHOOK: Input: default@daysales@dt=2001-01-01
POSTHOOK: Input: default@daysales@dt=2001-01-03
#### A masked pattern was here ####
1	2001-01-01
3	2001-01-03
PREHOOK: query: select * from daysales where (dt='2001-01-03' or customer=100)
PREHOOK: type: QUERY
PREHOOK: Input: default@daysales
PREHOOK: Input: default@daysales@dt=2001-01-01
PREHOOK: Input: default@daysales@dt=2001-01-03
#### A masked pattern was here ####
POSTHOOK: query: select * from daysales where (dt='2001-01-03' or customer=100)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@daysales
POSTHOOK: Input: default@daysales@dt=2001-01-01
POSTHOOK: Input: default@daysales@dt=2001-01-03
#### A masked pattern was here ####
3	2001-01-03
PREHOOK: query: explain extended select * from daysales where nvl(dt='2001-01-01' and customer=1, false)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from daysales where nvl(dt='2001-01-01' and customer=1, false)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: daysales
            Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: NVL((customer = 1),false) (type: boolean)
              Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: customer (type: int), dt (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: dt=2001-01-01
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              dt 2001-01-01
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              columns customer
              columns.comments 
              columns.types int
#### A masked pattern was here ####
              name default.daysales
              numFiles 1
              numRows 1
              partition_columns dt
              partition_columns.types string
              rawDataSize 1
              serialization.ddl struct daysales { i32 customer}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 2
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns customer
                columns.comments 
                columns.types int
#### A masked pattern was here ####
                name default.daysales
                partition_columns dt
                partition_columns.types string
                serialization.ddl struct daysales { i32 customer}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.daysales
            name: default.daysales
      Truncated Path -> Alias:
        /daysales/dt=2001-01-01 [daysales]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: explain extended select * from daysales where nvl(dt='2001-01-01' or customer=3, false)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from daysales where nvl(dt='2001-01-01' or customer=3, false)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: daysales
            Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: NVL(((dt = '2001-01-01') or (customer = 3)),false) (type: boolean)
              Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: customer (type: int), dt (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: dt=2001-01-01
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              dt 2001-01-01
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              columns customer
              columns.comments 
              columns.types int
#### A masked pattern was here ####
              name default.daysales
              numFiles 1
              numRows 1
              partition_columns dt
              partition_columns.types string
              rawDataSize 1
              serialization.ddl struct daysales { i32 customer}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 2
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns customer
                columns.comments 
                columns.types int
#### A masked pattern was here ####
                name default.daysales
                partition_columns dt
                partition_columns.types string
                serialization.ddl struct daysales { i32 customer}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.daysales
            name: default.daysales
#### A masked pattern was here ####
          Partition
            base file name: dt=2001-01-03
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              dt 2001-01-03
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              columns customer
              columns.comments 
              columns.types int
#### A masked pattern was here ####
              name default.daysales
              numFiles 1
              numRows 1
              partition_columns dt
              partition_columns.types string
              rawDataSize 1
              serialization.ddl struct daysales { i32 customer}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 2
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns customer
                columns.comments 
                columns.types int
#### A masked pattern was here ####
                name default.daysales
                partition_columns dt
                partition_columns.types string
                serialization.ddl struct daysales { i32 customer}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.daysales
            name: default.daysales
      Truncated Path -> Alias:
        /daysales/dt=2001-01-01 [daysales]
        /daysales/dt=2001-01-03 [daysales]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: explain extended select * from daysales where nvl(dt='2001-01-01' or customer=3, false)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from daysales where nvl(dt='2001-01-01' or customer=3, false)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: daysales
            Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: NVL(((dt = '2001-01-01') or (customer = 3)),false) (type: boolean)
              Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: customer (type: int), dt (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: dt=2001-01-01
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              dt 2001-01-01
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              columns customer
              columns.comments 
              columns.types int
#### A masked pattern was here ####
              name default.daysales
              numFiles 1
              numRows 1
              partition_columns dt
              partition_columns.types string
              rawDataSize 1
              serialization.ddl struct daysales { i32 customer}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 2
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns customer
                columns.comments 
                columns.types int
#### A masked pattern was here ####
                name default.daysales
                partition_columns dt
                partition_columns.types string
                serialization.ddl struct daysales { i32 customer}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.daysales
            name: default.daysales
#### A masked pattern was here ####
          Partition
            base file name: dt=2001-01-03
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              dt 2001-01-03
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              columns customer
              columns.comments 
              columns.types int
#### A masked pattern was here ####
              name default.daysales
              numFiles 1
              numRows 1
              partition_columns dt
              partition_columns.types string
              rawDataSize 1
              serialization.ddl struct daysales { i32 customer}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 2
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns customer
                columns.comments 
                columns.types int
#### A masked pattern was here ####
                name default.daysales
                partition_columns dt
                partition_columns.types string
                serialization.ddl struct daysales { i32 customer}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.daysales
            name: default.daysales
      Truncated Path -> Alias:
        /daysales/dt=2001-01-01 [daysales]
        /daysales/dt=2001-01-03 [daysales]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

